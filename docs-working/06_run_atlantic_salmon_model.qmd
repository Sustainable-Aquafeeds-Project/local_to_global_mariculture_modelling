---
title: "Run aquaculture model for Atlantic salmon"
format: html
editor: source
---

# Introduction

This document runs the aquaculture model for Atlantic salmon farms. It processes farm location data, species parameters, and conducts sensitivity analyses to understand the impact of various parameters on fish and farm growth measures.

```{r setup, include=F}
#| warning: false
#| message: false

library(arrow)
library(sf)
library(dplyr)
library(tidyr)
library(terra)
library(magrittr)
library(purrr)
library(furrr)
library(future)
library(tictoc)
library(ggplot2)
library(fs)
library(conflicted)
library(stringr)
library(readxl)
library(units)
library(qs)
library(here)
library(targets)
conflicted::conflicts_prefer(dplyr::filter(), dplyr::select(), .quiet = T)

here("src") %>% 
  list.files(pattern = "\\.R$", full.names = TRUE) %>% 
  str_subset("map", negate = T) %>% 
  walk(source)
```

```{r filenames}
#| code-summary: Set up global filenames

# Filenames
species_params_excel <- c(file = file.path(input_species_param_path, "Species.xlsx"), sheet = "Atlantic salmon")
pop_params_excel <- c(file = file.path(input_species_param_path, "Population.xlsx"))
farm_locations_parquet <- file.path(input_farm_coords_path, "farm_coords.parquet")
farm_coords_file <- file.path(output_farm_data_path, "farm_coords.qs")
farm_geometry_file <- file.path(output_farm_data_path, "farm_geometry.qs")
farm_ts_data_file <- file.path(output_farm_data_path, "farm_ts_data.qs")
species_params_file <- file.path(output_species_data_path, "species_params.qs")
sens_params_file <- file.path(output_species_data_path, "sens_params.qs")
pop_params_file <- file.path(output_species_data_path, "pop_params.qs")
feed_params_file <- file.path(output_species_data_path, "feed_params.qs")
farm_harvest_file <- file.path(output_farm_data_path, "farm_harvest_size.qs")
```

# Data for targets pipelines

Much of the actual analysis is run through targets pipelines. Therefore, we need to make sure that the files going into those pipelines are correct and up to date. 

```{r farm-coordinates}
#| code-summary: Load and process farm coordinate data with appropriate timing parameters for Northern and Southern hemisphere farms

times_N <- c("t_start" = 121, "t_end" = 121+547, "dt" = 1)
times_S <- c("t_start" = 274, "t_end" = 274+547, "dt" = 1)

farm_coords <- farm_locations_parquet %>% 
  read_parquet() %>% 
  mutate(t_start = case_when(lat > 0 ~ times_N['t_start'], TRUE ~ times_S['t_start']), 
          t_end = case_when(lat > 0 ~ times_N['t_end'], TRUE ~ times_S['t_end']),
          t_start = unname(t_start),
          t_end = unname(t_end))

qsave(farm_coords, farm_coords_file)

# Also save geometry for later
file.path(input_farm_coords_path, "atlantic_salmon_locations_w_temps.qs") %>% 
  qread() %>% 
  dplyr::filter(day == "day_1") %>% 
  dplyr::select(farm_id, geometry, country) %>% 
  qsave(farm_geometry_file)
```

## Farm Time Series Data

Process Sea Surface Temperature (SST) data for each farm location.

```{r farm-sst-data}
#| label: farm-ts-data

farms_to_omit <- qread(sprintf(file.path(input_farm_coords_path, "%s_farms_to_omit.qs"), this_species))
farm_SST_data <- read_parquet(file.path(input_farm_sst_path, "farm_SST_extracted.parquet"))
farm_IDs <- farm_SST_data %>%
  filter(!farm_id %in% farms_to_omit) %>%
  distinct(farm_id) %>%
  pull(farm_id)

farm_ts_data <- farm_SST_data %>%
  rename(farm_ID = farm_id) %>% 
  select(c(farm_ID, day, temp_c)) %>%
  mutate(day = str_split_i(day, "day_", 2) %>% as.integer())

qsave(farm_ts_data, farm_ts_data_file)
```

## Species and population parameters

```{r species-parameters}
#| code-summary: Load species-specific parameters from Excel file

species_params <- readxl::read_excel(
  path = species_params_excel["file"], 
  sheet = species_params_excel["sheet"]
)
vals <- species_params$Value
names(vals) <- species_params$Quantity
species_params <- vals[!is.na(vals)]
qsave(species_params, species_params_file)
```

```{r population-parameters}
#| code-summary: Load population-specific parameters

pop_params <- readxl::read_excel(path = pop_params_excel["file"])
vals <- pop_params$Value
names(vals) <- pop_params$Quantity
pop_params <- vals[!is.na(vals)]
qsave(pop_params, pop_params_file)
```

## Feed digestibility

```{r variable-digestibility}
#| code-summary: Show the variability in feed digestibility generated by sampling digestibility values.

Sys.setenv(TAR_PROJECT = "project_farmruns")

# tar_make(names = c("feed_params", "feed_names"))

tar_load(feed_params)
tar_load(feed_names)

feed_params <- feed_params %>% 
  map2_dfr(., feed_names, function(fp, fn) {
    ld <- filter(fp[["Lipids"]], macro != 0)
    ld <- sum(ld$proportion * ld$digest)/sum(ld$proportion)

    cd <- filter(fp[["Carbohydrates"]], macro != 0)
    cd <- sum(cd$proportion * cd$digest)/sum(cd$proportion)

    pd <- filter(fp[["Proteins"]], macro != 0)
    pd <- sum(pd$proportion * pd$digest)/sum(pd$proportion)

    data.frame(
      protein_digestibility = pd,
      carb_digestibility = cd,
      lipid_digestibility = ld,
      feed_name = fn
    )
  }) %>% 
  pivot_longer(
    cols = contains("digestibility"),
    names_to = "macro", 
    values_to = "digestibility"
  ) %>% 
  mutate(
    macro = factor(
      macro, 
      levels = c("protein_digestibility", "lipid_digestibility", "carb_digestibility"),
      labels = c("protein", "lipid", "carb")
    ))

feed_params %>% 
  ggplot(aes(x = macro, y = digestibility, fill = feed_name)) +
  geom_col(position = position_dodge(), alpha = 0.35) +
  theme_classic()
```

# Farm Harvest Size Calculations

Calculations of expected harvest sizes for each farm (using default feed and no Monte-Carlo variation) are done in the targets pipeline. This also allows you to run some tests and make sure the pipeline is running correctly.

```{r check-farmrun-pipeline}
#| code-summary: Check that the pipeline will run correctly

Sys.setenv(TAR_PROJECT = "project_farmruns")
# tar_validate()
# tar_prune()

# tar_make(test_reference_feed)
tar_read(test_reference_feed) # if weight ~ 0 then feeds aren't processing properly
```

```{r farm-harvest-size, eval=F}
#| code-summary: Run limited pipeline for harvest sizes and testing

Sys.setenv(TAR_PROJECT = "project_farmruns")

# Get harvest sizes for all farms
tar_make(names = contains(c("harvest_size", "feed_params")))
```

```{r save-harvest-size}
#| code-summary: Save harvest size data

tar_load(harvest_size_chunked)
harvest_size <- bind_rows(harvest_size_chunked)

ggplot(harvest_size, aes(x = weight)) +
  geom_histogram(fill = "salmon", alpha = 0.75, colour = "black")

qsave(harvest_size, farm_harvest_file)
```

# Sensitivity analysis

Run the sensitivity runs using the targets pipeline - note that this can take a long time. The species parameters (n=19) are run for a single fish in  a sample number of farms (n=272) and each factor (3). The population parameters (n=6) are run for 1000 fish in a sample number of farms (271) and each factor (3). 

```{r check-sensitivity-pipeline}
#| code-summary: Check that the sensitivities pipeline is running correctly

Sys.setenv(TAR_PROJECT = "project_sensitivities")
# tar_validate()
# tar_visnetwork(targets_only = T)

# tar_make(test_reference_feed)
tar_read(test_reference_feed) # if weight ~ 0 then feeds aren't processing properly, fix before proceeding
```

```{r sensitivity-run, eval=F}
#| code-summary: Run sensitivity pipeline

Sys.setenv(TAR_PROJECT = "project_sensitivities")

tar_make(seconds_meta_append = 300)
tar_prune()
```

## Process sensitivity results

Combine and visualise sensitivity analysis results.

```{r sensitivity-results}
#| code-summary: Plot and save sensitivity results

tar_load(sens_results_spec)
tar_load(sens_results_pop)

sens_results <- rbind(
  sens_results_pop,
  sens_results_spec
)

qsave(sens_results, file.path(output_sens_data_path, paste0("sens_results_all.qs")))

sens_measures <- levels(sens_results$measure)
sens_results_figfiles <- file.path(output_sens_data_path, paste0("sens_plot_", sens_measures, ".qs"))
sens_results_figfiles2 <- file.path(output_sens_data_path, paste0("sens_plot_", sens_measures, ".png"))

for (sm in seq_along(sens_measures)) {
  p <- sens_results %>% 
    filter(measure == sens_measures[sm]) %>% 
    ggplot(aes(x = adj_param, y = mean_sens, ymin = mean_sens-sd_sens, ymax = mean_sens+sd_sens)) +
    geom_col(fill = "salmon", alpha = 0.65, colour = "black") +
    geom_errorbar(width = 0.5) +
    coord_flip() +
    theme_classic()
  qsave(p, sens_results_figfiles[sm])
  ggsave(sens_results_figfiles2[sm])
}
```

# Run farms

The following code runs the main pipeline in two stages. The pre-run prepares all the pre-requisites for the main results targets, to reduce load. The main run shortcuts past all the pre-run targets and does the main model runs and results processing. 

```{r run-farms-pipeline, eval=F}
#| code-summary: Run the main pipeline

Sys.setenv(TAR_PROJECT = "project_farmruns")

# Pre-run to reduce load
tar_make(
  names = contains(c("data", "feed")),
  seconds_meta_append = 90
)

# tar_outdated()

# Run results
tar_make(
  names = c("farm_run_chunked", "farm_full_results"), 
  seconds_meta_append = 120,
  shortcut = T # only if you've done the pre-run, above
)
```

Load objects from the targets pipeline and save them as .qs files, which are much quicker to load down the line. This takes a few minutes to gather all the targets.

```{r all-farms-cohorts-results}
#| code-summary: Save pipeline objects as files

tar_load(stat_names)
tar_load(farm_IDs_chunked)
farm_IDs_chunked <- farm_IDs_chunked %>% unlist()
tar_load(feed_names)

print("Loading farm results...")
tar_load(farm_results_chunked)
farm_results_chunked <- farm_results_chunked %>% 
  bind_rows()
for (stat_name in stat_names) {
  farm_results_chunked %>% 
      filter(measure == stat_name) %>% 
      qsave(file.path(output_model_farm_path, str_c(stat_name, "_all_farms.qs")))
}
rm(farm_results_chunked)

print("Loading cohort results...")
tar_load(cohort_results_chunked)
cohort_results_chunked <- cohort_results_chunked %>% 
  bind_rows()
for (stat_name in stat_names) {
  cohort_results_chunked %>% 
      filter(measure == stat_name) %>% 
      qsave(file.path(output_model_cohort_path, str_c(stat_name, "_all_farms.qs")))
}
rm(cohort_results_chunked)

tar_load(biomass_produced_chunked)
qsave(biomass_produced_chunked, file.path(output_model_farm_path, str_c("biomass_produced_all_farms.qs")))
rm(biomass_produced_chunked)
```
